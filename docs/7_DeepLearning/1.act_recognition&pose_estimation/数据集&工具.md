# 行为识别-数据集&工具

## 1.数据集-动态视频

| 数据 | 基本情况 | 链接 |
| --- | --- | --- |
| HMDB-51 | 51个类别，6766个视频 | https://serre-lab.clps.brown.edu/resource/hmdb-a-large-human-motion-database/#dataset |
| UCF-101 | 101类别，13320个短视频 | https://www.crcv.ucf.edu/research/data-sets/ucf101/  |
| Kinetics-700 | 650000个，用于ActivityNet比赛 | https://deepmind.com/research/open-source/open-source-datasets/kinetics/ |
| ava | google。多人不同动作数据集 | https://research.google.com/ava/explore.html |
| ActivityNet | | |

HMDB-51: 压缩包大概6G，主要包含类别
- 常见面部动作（smile，laugh，chew，talk）
- 复杂面部动作
- 直梯动作
- 多人交互

![-w971](../../../Draft/media/15899772943822/15913243160558.jpg)
![-w1001](../../../Draft/media/15899772943822/15913243437161.jpg)


UCF-101: 包含的数据类型
- 人物交互
- 人体动作
- 人人交互
- 乐器演奏
- 体育运动


Kinetics
- 单人行为，例如绘画，喝酒，大笑，抽拳;
- 人人行为，例如拥抱，亲吻，握手；
- 人物行为，例如打开礼物，修剪草坪，洗碗。

**ava-action：**
包含了80个原子动作(比如走路，握手。。) 数据包含三部分:
- person pose：
- 人-物交互
- 人人交互
https://research.google.com/ava/explore.html
一共430个video，其中235个train， 64个validation，131 test。 每个视频是15min，每1s钟进行以此标注。
有一个机遇faster-rcnn的预训练模型。 tensorflow的目标检测api https://github.com/tensorflow/models/tree/master/research/object_detection#tensorflow-object-detection-api

数据格式 ava_train_v2.2.csv
video_id, middle_frame_timestamp, person_box, action_id, person_id

stand, sit, watch some body, listen to sb....

toread
https://www.jianshu.com/p/a4cc71126796


## 2.数据集-静态图像

https://blog.csdn.net/lgk1996/article/details/79814888


| data | basic description | link |
| --- | --- | --- |
| Stanford40 Dataset | 斯坦福-李飞飞团队穿件，包括40中不同的行为类别，9532张图片 | http://vision.stanford.edu/Datasets/40actions.html |
| MPII Pose Dataset | 主要是human pose estimation| |


**Stanford40 Dataset**: runing, phoning, play,drinking等, taking photos
B. Yao, X. Jiang, A. Khosla, A.L. Lin, L.J. Guibas, and L. Fei-Fei. Human Action Recognition by Learning Bases of Action Attributes and Parts. Internation Conference on Computer Vision (ICCV), Barcelona, Spain. November 6-13, 2011. 

**MPII Pose Dataset**
![](../../../Draft/media/15899772943822/15917594608821.jpg)



## 3.工具

常用的工具：
https://zhuanlan.zhihu.com/p/38597956


| tool | 说明 | 语言 | 链接 |
| --- | --- | --- | --- |
| openpose | 多人，2D，实时 | python-API | https://github.com/CMU-Perceptual-Computing-Lab/openpose |
| facebook-densePose | mask-RCNN的变体 |  |  github.com/facebookresearch/Densepose|
| alphaPose |  | tf, pytorch |  |
| Human Body Pose Estimation |  |  |  |
| Deeppose(2014) |  |  |  |


### (1)Open-mmlab家族
**MMSkeleton**
原理的名字叫 st-gcn，后来改为 MMSkeleton
st-gcn: 比较老了 https://hub.docker.com/r/jaehwankimneo/st-gcn
mmskelton: https://hub.docker.com/r/ioir123ju/mmskeleton/tags

```
python setup.py develop
```
中间可能会报很多错，需要一步步的改
环境配置http://blog.sina.com.cn/s/blog_679f93560102wpyf.html

安装好mmskelton后，可以选安装mmdetection，这个参照其github上的说明来就行

**mmcv**

mmcv是一个MMLAB开发的cv的基础工具库，用来支持mmdetection，mmaction等

### (2)openpose

运行方式:
1. 命令行: ./build/examples/openpose/openpose.bin xxx
2. c++接口
3. Python接口

docker: `docker pull exsidius/openpose`

还有在google colab上进行尝试https://github.com/CMU-Perceptual-Computing-Lab/openpose/issues/949#issue-387855863

```
! apt update
! apt install -y cmake sudo libopencv-dev
! git clone https://github.com/CMU-Perceptual-Computing-Lab/openpose.git
! cd openpose/ubuntu && ./install_cmake.sh && ./install_cuda.sh && ./install_cudnn.sh
! cd openpose && git pull origin master && rm -r build || true && mkdir build && cd build && cmake .. && make -j`nproc`

# example demo usage
!cd openpose && ./build/examples/openpose/openpose.bin --video examples/media/video.avi --write_json output/ --display 0 --render_pose 0
```

cpu-only的版本：要求8G内存

安装
```
git clone https://github.com/CMU-Perceptual-Computing-Lab/openpose
cd build/
make -j`nproc`
```


### (3) gluon
https://gluon-cv.mxnet.io/model_zoo/action_recognition.html