#todo 

概述
• 利用数据集：大型语料库——大量自然语言句子的集合
• 模型目的：预测句子出现的概率
• 主要知识点：链式法则，大数定理

## 语言模型-问题描述
假设一个句子 W = (w1, w2,....wT)， 由T个词按照顺序组成，则句子的概率模型就是w1,w2,...wt的联合概率,即:
$$P(w) = P(w_1, w_2, ...w_t) = p(w_1)p(w_2|w_1)p(w_3|w1,w2)...$$

但是实际操作的时候，计算每个的条件概率，这个参数空间太多了。


具体计算的时候有如下几种方式：
- n-gram
- 决策树
- 条件随机场
- 神经网络

## n-gram模型

考虑$p(w_k|w_1,..w_{k-1})$的近似计算，根据贝叶斯公式以及大数定律有：
$$p=p(w1,...w_k)/p(w_1,...w_{k-1})≈ count(w_1,...w_k) / count(w_1,...w_{k-1})$$

容易知道，如果k很大时候，要计算这个共线串的count，会比较耗时。

n-gram的一个假定就是，一个词只与他前面的n-1个词有关，从而做了简化。每次通过滑动窗口，提取长度为n的词组作为一个训练样本。

实际应用中，n一般取3




## 参考

https://zhuanlan.zhihu.com/p/32829048