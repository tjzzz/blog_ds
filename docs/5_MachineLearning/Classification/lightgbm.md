
# lightgbm

## 基础改进
相比于[xgboost](xgboost.md)，lightgbm的改进：https://zhuanlan.zhihu.com/p/85044159


1 Histogram算法
直方图算法的基本思想是`先把连续的浮点特征值离散化成k个整数`（其实又是分桶的思想，而这些桶称为bin，同时构造一个宽度为k的直方图。

在遍历数据的时候，根据离散化后的值作为索引在直方图中累积统计量，当遍历一次数据后，直方图累积了需要的统计量，然后`根据直方图的离散值，遍历寻找最优的分割点`。

> **优点**： 首先，最明显就是内存消耗的降低，直方图算法不仅不需要额外存储预排序的结果，而且可以只保存特征离散化后的值，而这个值一般用8位整型存储就足够了，内存消耗可以降低为原来的1/8。然后在计算上的代价也大幅降低，预排序算法每遍历一个特征值就需要计算一次分裂的增益，而直方图算法只需要计算k次


2 **带深度限制的Leaf-wise的叶子生长策略**： 简单理解一个广度遍历、一个深度遍历

在XGBoost中，树是`按层生长的`，称为Level-wise tree growth，同一层的所有节点都做分裂，最后剪枝，如下图所示： 

![](https://pic3.zhimg.com/80/v2-baa416037f10e088df7b78ce7017bb5a_1440w.jpg)

Level-wise过一次数据可以同时分裂同一层的叶子，容易进行多线程优化，也好控制模型复杂度，不容易过拟合。但实际上Level-wise是一种低效的算法，因为它`不加区分的对待同一层的叶子，带来了很多没必要的开销，因为实际上很多叶子的分裂增益较低`，没必要进行搜索和分裂。

在Histogram算法之上，LightGBM进行进一步的优化，采用的Leaf-wise则是一种更为高效的策略，`每次从当前所有叶子中，找到分裂增益最大的一个叶子，然后分裂，如此循环`。
  
![](https://pic4.zhimg.com/80/v2-067b8468a94c76b32f3d92b80fd50e2f_1440w.jpg)

**3.直方图差加速**

在树中，`一个叶子的直方图可以由它的父亲节点的直方图与它兄弟的直方图做差得到`。利用这个方法，LightGBM可以在构造一个叶子的直方图后，可以用非常微小的代价得到它兄弟叶子的直方图，在速度上可以提升一倍。 

**4.直接支持类别特征**

一般算法，需要把类别特征转化到多维的0/1特征，然而会降低了空间和时间的效率。 LightGBM优化了对类别特征的支持，可以直接输入类别特征，不需要额外的0/1展开



## 工具使用

https://bacterous.github.io/2018/09/13/LightGBM%E4%BD%BF%E7%94%A8/


处理类别特征:https://blog.csdn.net/u013385018/article/details/104167969
在使用python API时(参考官方文档)
1.可以使用pd.DataFrame存放特征X, 每一列表示1个特征, 将类别特征设置为X[cat_cols].astype('category'). 这样模型在fit时会自动识别类别特征.
2.在模型的fit方法中传入参数categorical_feature, 指明哪些列是类别特征.
3.类别特征的值必须是从0开始的连续整数, 比如0,1,2,..., 不能是负数.


官方文档：
https://lightgbm.readthedocs.io/en/latest/Parameters.html#categorical_feature

模型参数
