# 相关系数
对于两个连续型变量，相关系数是一个比较好的衡量两个变量之间关系的度量方式。

相关系数的检验:

$H_0: \rho = 9; H_1: \rho \ne 0$
检验的统计量是
$$t=\frac{r\sqrt{n-2}}{\sqrt{1-r^2}} - t(n-2)$$
# 多元线性回归模型
一元回归比较简单，属于多元的一个特例，所以这里只列举多元线性回归的情况。
$$y =\beta_0 + \beta_1 x_1 + ...+\beta_k x_k + e$$
其中对误差项e的三个基本假定：
- 正态性。随机误差是一个服从正态分布的随机变量，期望是0
- 方差齐性
- 独立性


参数的最小二乘估计



## 模型效果评估

- 多重判定系数：$R^2=SSR/SST$

- 调整的多重判定系数：
$$R^2_{adj}=1 - (1-R^2)\frac{n-1}{n-k-1}$$
考虑到一般随着变量个数的增加，模型整体的R^2一般都会增加。所以考虑变量个数这个因素，需要做一个调整。

- 估计的标准误差。
估计的标准误差即残差平方和的平方根。
$$s_2 = \sqrt{SSE/(n-k-1)}$$

## 显著性检验
单系数的t-test
模型整体的 F-test


## 异方差

## 多重共线性

### 可能会带来的问题
- 参数估计的不准确
- 回归系数的正负号可能完全相反


### 如何识别：
- 计算变量之间的相关系数，并对其进行显著性检验
- 计算VIF： 对第j个变量将其作为Y和其他x进行回归，计算R_j,则方差膨胀因子
$$VIF_j = 1/(1-R^2_j)$$


### 解决方式
变量选择与逐步回归

1. 向前选择： 向前选择，即模型中本来没有变量，然后按照如下的步骤选择自变量来拟合模型
- 首先：分别拟合y对k个自变量的医院回归模型，找到其中F统计量最大的模型及其自变量，并将该自变量纳入到模型中
- 在模型已经纳入$x_i$的基础上，再分别从生下的变量中依次挑选变量纳入模型，选择F 统计量最大的那个，如果没有一个是显著的，则终止。
- 重复上面步骤，不断引入新的变量

2. 向后剔除
拟合因变量对所有k个自变量的线性回归模型，然后依次去掉一个变量，选择使模型的SSE减小最小的自变量(F统计量的值最小)从模型中提出，
依次执行如上操作

3. 逐步回归
逐步回归是避免多重共线性的有效方法之一，是将前向选择和向后剔除结合起来进行筛选的方法。前面步骤与前向选择方式一样，但是在新增一个自变量后，会模型中所有变量进行检查看有没有可能剔除某个自变量(即新增的导致前面某个贡献不显著了这个变量就会被踢出)

# 正则化模型